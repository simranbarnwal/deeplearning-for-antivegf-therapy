{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training The Proposed SimpleNet Model over the entire training set\n",
    "## Description of Notebook\n",
    "The notebook contains code used for training the proposed SimpleNet model. \n",
    "The model classifies preprocessed retinal OCT scans into three categories: urgent referral, routine referral\n",
    "and normal. Since, the best performing model should be chosen among all trained model, we trained a total of 10 models and selected the best one.\n",
    "\n",
    "## Description of SimpleNet Model\n",
    "In the publication, a small CNN architecture with 30,793 parameters is used as the\n",
    "classifier. The proposed SimpleNet consists of four convolutional layers, two\n",
    "batch normalization layers, two max-pooling layers, and a final fully connected\n",
    "output layer consisting of three nodes with softmax activation function. The training process uses Adam as the optimizer with a learning rate of 0.001,\n",
    "while the “categorical cross-entropy” cost function is used to train the output\n",
    "layer. The training was performed in batches of 128 images per step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "* [1. Importing all modules](#1)\n",
    "* [2. Loading train and test data](#2)\n",
    "* [3. Generator Classes using Sequence class](#3)\n",
    "* [4. Functions for building and loading the transfer learning model](#4)\n",
    "* [5. Functions for training and testing](#5)\n",
    "* [6. Training the proposed SimpleNet model on entire training data](#6)\n",
    "* [7. Performance metrics of proposed SimpleNet model on testing set](#7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "### 1. Importing all modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from scipy.misc import imread\n",
    "get_ipython().magic('matplotlib inline')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import Sequence\n",
    "from cv2 import * #Import functions from OpenCV\n",
    "import cv2\n",
    "import glob\n",
    "from skimage.transform import resize\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense, Dropout, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import model_from_json\n",
    "import json\n",
    "from statistics import mean\n",
    "from sklearn.utils import shuffle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "### 2. Loading train and test data\n",
    "Entire training data is loaded and shuffled randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = glob.glob(\"../input/no-med-filt-60/no_median_filter_60_200/no_median_filter_60_200/train/CNV/*.jpeg\");\n",
    "img = img + glob.glob(\"../input/no-med-filt-60/no_median_filter_60_200/no_median_filter_60_200/train/DME/*.jpeg\");\n",
    "l = len(img);\n",
    "y = np.zeros((l,3))\n",
    "y[:,2] =1\n",
    "img = img + glob.glob(\"../input/no-med-filt-60/no_median_filter_60_200/no_median_filter_60_200/train/DRUSEN/*.jpeg\");\n",
    "m = len(img);\n",
    "k = np.zeros((m-l,3));\n",
    "k[:,1] = 1;\n",
    "y = np.append(y,k, axis =0);\n",
    "img = img + glob.glob(\"../input/no-med-filt-60/no_median_filter_60_200/no_median_filter_60_200/train/NORMAL/*.jpeg\");\n",
    "k = np.zeros((len(img)-m,3));\n",
    "k[:,0] = 1;\n",
    "y = np.append(y,k, axis =0);\n",
    "\n",
    "img, y = shuffle(img,y)\n",
    "img, y = shuffle(img,y)\n",
    "img, y = shuffle(img,y)\n",
    "img, y = shuffle(img,y)\n",
    "img, y = shuffle(img,y)\n",
    "\n",
    "\n",
    "t_img = []\n",
    "\n",
    "for images in glob.glob(\"../input/no-med-filt-60/no_median_filter_60_200/no_median_filter_60_200/test/CNV/*.jpeg\"):\n",
    "    n = resize(imread(images,0), (60, 200,1))\n",
    "    t_img.append(n)\n",
    "    \n",
    "for images in glob.glob(\"../input/no-med-filt-60/no_median_filter_60_200/no_median_filter_60_200/test/DME/*.jpeg\"):\n",
    "    n = resize(imread(images,0), (60, 200,1))\n",
    "    t_img.append(n)\n",
    "    \n",
    "l = len(t_img);\n",
    "t_y = np.zeros((l,3))\n",
    "t_y[:,2] =1\n",
    "  \n",
    "for images in glob.glob(\"../input/no-med-filt-60/no_median_filter_60_200/no_median_filter_60_200/test/DRUSEN/*.jpeg\"):\n",
    "    n = resize(imread(images,0), (60, 200,1))\n",
    "    t_img.append(n)    \n",
    "\n",
    "     \n",
    "m = len(t_img);\n",
    "k = np.zeros((m-l,3));\n",
    "k[:,1] = 1;\n",
    "t_y = np.append(t_y,k, axis =0);\n",
    "    \n",
    "    \n",
    "for images in glob.glob(\"../input/no-med-filt-60/no_median_filter_60_200/no_median_filter_60_200/test/NORMAL/*.jpeg\"):\n",
    "    n = resize(imread(images,0), (60, 200,1))\n",
    "    t_img.append(n)\n",
    "    \n",
    "k = np.zeros((len(t_img)-m,3));\n",
    "k[:,0] = 1;\n",
    "t_y = np.append(t_y,k, axis =0);\n",
    "\n",
    "t_img = np.asarray(t_img)\n",
    "t_y = np.asarray(t_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "### 3. Generator Classes using Sequence class\n",
    "Since our training dataset is large, we would use the Sequence class to help us feed images in batches for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "93cad25f972ed8e4d3edfb8a18ccaaad21157f03",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class My_Generator(Sequence):\n",
    "\n",
    "    def __init__(self, image_filenames, labels, batch_size):\n",
    "        self.image_filenames, self.labels = image_filenames, labels\n",
    "        self.batch_size = batch_size\n",
    "        self.n = len(image_filenames)\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.image_filenames) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx_min = idx*self.batch_size\n",
    "        idx_max = np.amin([((idx+1)*self.batch_size),self.n])\n",
    "        batch_x = self.image_filenames[idx_min:idx_max]\n",
    "        batch_y = self.labels[idx_min:idx_max]\n",
    "        X = np.array([\n",
    "            resize(imread(file_name,0), (60, 200,1))\n",
    "               for file_name in batch_x])\n",
    "        y = np.array(batch_y)\n",
    "        X, y = shuffle(X,y)\n",
    "        return X,y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "### 4. Functions for building and loading the transfer learning model\n",
    "\n",
    "build_model() builds the architecture of proposed SimpleNet model whereas load_ith_model() \n",
    "loads the ith trial model from memory for testing. \n",
    "\n",
    "build_model_best() retrieves the model at its best performing epoch.\n",
    "\n",
    "The proposed model has just **30,793** parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    #load vgg16 without dense layer and with theano dim ordering\n",
    "    model = Sequential()\n",
    "        \n",
    "    model.add(Conv2D(filters = 20, kernel_size = (5,5), input_shape = (60,200,1), activation = 'relu'))\n",
    "    model.add(Conv2D(filters = 20, kernel_size = (5,5), activation = 'relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size = (4, 4)))\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(filters = 40, kernel_size = (3,3), activation = 'relu'))\n",
    "    model.add(Conv2D(filters = 30, kernel_size = (3,3), activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size = (4, 4)))\n",
    "    \n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units = 3, activation = 'softmax'))\n",
    "\n",
    "    #compile the model\n",
    "    model.compile(optimizer=Adam(lr = 0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def load_ith_model(i):\n",
    "    json_file = open('model-'+str(i)+'.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    model.load_weights('model-'+str(i)+'.h5')\n",
    "\n",
    "    #compile the model\n",
    "    model.compile(optimizer=Adam(lr = 0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_model_best(i):\n",
    "    json_file = open('bestmodel-'+str(i)+'.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    model.load_weights('bestmodel-'+str(i)+'.h5')\n",
    "\n",
    "    #compile the model\n",
    "    model.compile(optimizer=Adam(lr = 0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "### 5. Functions for training and testing\n",
    "For each trial model i, train_save(i) trains the model, saves model-i and saves model-i at its best performing epoch. \n",
    "\n",
    "test_performance(i) loads the best_model of trial i and return the performance metrics of the model on the text set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_save(i):\n",
    "    \n",
    "    batch_size = 128\n",
    "\n",
    "    trainGenerator = My_Generator(img,y,batch_size)\n",
    "    valacc = 0.0\n",
    "    for j in range(1,11):\n",
    "        if j==1:\n",
    "            model = build_model()\n",
    "            if i==1 and j==1:\n",
    "                model.summary()\n",
    "        else:\n",
    "            model = load_ith_model(i)\n",
    "        history = model.fit_generator(\n",
    "            generator = trainGenerator,\n",
    "            steps_per_epoch=(len(img)//batch_size),\n",
    "            epochs=1, verbose = 2, class_weight = [0.70596402, 4.19022748, 0.74357918], validation_data = (t_img,t_y))\n",
    "        model_json = model.to_json()\n",
    "        with open('model-'+str(i)+'.json', \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "        # serialize weights to HDF5\n",
    "        model.save_weights('model-'+str(i)+'.h5')\n",
    "        \n",
    "        if history.history['val_acc'][-1]>valacc:\n",
    "            model_json = model.to_json()\n",
    "            with open('bestmodel-'+str(i)+'.json', \"w\") as json_file:\n",
    "                json_file.write(model_json)\n",
    "            # serialize weights to HDF5\n",
    "            model.save_weights('bestmodel-'+str(i)+'.h5')\n",
    "            valacc = history.history['val_acc'][-1]\n",
    "            \n",
    "def test_performance(i):\n",
    "    perf = {}\n",
    "    \n",
    "    for j in range(1,6):\n",
    "        model = build_model_best(i)      \n",
    "        ans = model.predict(t_img\n",
    "        ans = np.argmax(ans, axis =1)\n",
    "        perf[j]=performance_metrics(np.argmax(t_y, axis = 1),ans)\n",
    "                            \n",
    "    print(\"TEST ACCURACIES for Simple Net ##\",i,\"##\")\n",
    "    print_performance(perf)\n",
    "    return perf[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**perfromance_metrics()** derives all performance measures from the confusion matrix whereas **print_performance()** prints the testing metrics in a readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def performance_metrics(t_y,ans):\n",
    "    acc = accuracy_score(t_y,ans)\n",
    "    target_names = ['CLass Normal', 'CLass Early', 'Class Late']\n",
    "    cm = confusion_matrix(t_y, ans) \n",
    "    sens0 = cm[0,0]/(cm[0,0]+cm[0,1]+cm[0,2])\n",
    "    spec0 = (cm[1,1]+cm[1,2]+cm[2,1] +cm[2,2])/((cm[1,1]+cm[1,2]+cm[2,1] +cm[2,2])+(cm[1,0]+cm[2,0]))\n",
    "\n",
    "    sens1 = cm[1,1]/(cm[1,0]+cm[1,1]+cm[1,2])\n",
    "    spec1 = (cm[0,0]+cm[2,0]+cm[0,2] +cm[2,2])/((cm[0,0]+cm[2,0]+cm[0,2] +cm[2,2])+(cm[0,1]+cm[2,1]))\n",
    "\n",
    "    sens2 = cm[2,2]/(cm[2,0]+cm[2,1]+cm[2,2])\n",
    "    spec2 = (cm[0,0]+cm[0,1]+cm[1,0] +cm[1,1])/((cm[0,0]+cm[0,1]+cm[1,0] +cm[1,1])+(cm[0,2]+cm[1,2]))\n",
    "  \n",
    "    rep=classification_report(t_y, ans, target_names=target_names, digits = 4, labels=range(0,3),output_dict=True)\n",
    "    return [acc,sens0,spec0,sens1,spec1,sens2,spec2],cm,rep\n",
    "\n",
    "\n",
    "def print_performance(p):\n",
    "    a = list(p[1][2].keys())\n",
    "    b = list(p[1][2][a[0]].keys())\n",
    "\n",
    "    for i in range (0,1):\n",
    "        s = np.zeros(7)\n",
    "        pn = pe = pl = fn = fe = fl = rn = re = rl = 0\n",
    "        for j in range(1,6):\n",
    "            s = s + p[j][0]\n",
    "            pn = pn +  p[j][2][a[0]][b[0]]\n",
    "            pe = pe +  p[j][2][a[1]][b[0]]\n",
    "            pl = pl +  p[j][2][a[2]][b[0]]\n",
    "            fn = fn + p[j][2][a[0]][b[2]]\n",
    "            fe = fe + p[j][2][a[1]][b[2]]\n",
    "            fl = fl +  p[j][2][a[2]][b[2]]\n",
    "            rn = rn +  p[j][2][a[0]][b[1]]\n",
    "            re = re +  p[j][2][a[1]][b[1]]\n",
    "            rl = rl +  p[j][2][a[2]][b[1]]\n",
    "\n",
    "        print('\\nAccuracy = ',round(s[0]*20,2))\n",
    "        print(\"\\n              sensitivity  specificity      precision      f1-score\")\n",
    "        print('\\nClass Normal: ',round(s[1]*20,2), \",       \", round(s[2]*20,2), \",       \", round(pn*20,2),\",       \", round(fn*20,2))\n",
    "        print('\\nClass Early:  ',round(s[3]*20,2), \",       \", round(s[4]*20,2), \",       \", round(pe*20,2),\",       \", round(fe*20,2))\n",
    "        print('\\nClass Late:   ',round(s[5]*20,2), \",       \", round(s[6]*20,2), \",       \", round(pl*20,2),\",       \", round(fl*20,2))\n",
    "\n",
    "        print('\\nAverage')\n",
    "        print('\\nsensitivity: ',round(mean([s[1],s[3],s[5]])*20,2), \", specificity: \",round(mean([s[2],s[4],s[6]])*20,2),\n",
    "              \", precision: \", round(mean([pn,pe,pl])*20,2),\", f1-score: \", round(mean([fn,fe,fl])*20,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <a id=\"6\"></a>\n",
    "### 6. Training the proposed SimpleNet model on entire training data\n",
    "This cell is not executed in this notebook as each training will yield different results. Kindly send me an email if you need the trained weights used in the publication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 56, 196, 20)       520       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 52, 192, 20)       10020     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 52, 192, 20)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 52, 192, 20)       80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 48, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 46, 40)        7240      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 9, 44, 30)         10830     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 9, 44, 30)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9, 44, 30)         120       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 11, 30)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 660)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 1983      \n",
      "=================================================================\n",
      "Total params: 30,793\n",
      "Trainable params: 30,693\n",
      "Non-trainable params: 100\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      " - 244s - loss: 0.3249 - acc: 0.8864 - val_loss: 0.5141 - val_acc: 0.8100\n",
      "Epoch 1/1\n",
      " - 247s - loss: 0.2012 - acc: 0.9326 - val_loss: 0.2372 - val_acc: 0.9200\n",
      "Epoch 1/1\n",
      " - 247s - loss: 0.1665 - acc: 0.9441 - val_loss: 0.1679 - val_acc: 0.9400\n",
      "Epoch 1/1\n",
      " - 251s - loss: 0.1511 - acc: 0.9496 - val_loss: 0.4412 - val_acc: 0.8550\n",
      "Epoch 1/1\n",
      " - 247s - loss: 0.1398 - acc: 0.9536 - val_loss: 0.1322 - val_acc: 0.9500\n",
      "Epoch 1/1\n",
      " - 247s - loss: 0.1330 - acc: 0.9555 - val_loss: 0.5459 - val_acc: 0.8430\n",
      "Epoch 1/1\n",
      " - 249s - loss: 0.1260 - acc: 0.9581 - val_loss: 0.3437 - val_acc: 0.8720\n",
      "Epoch 1/1\n",
      " - 246s - loss: 0.1191 - acc: 0.9600 - val_loss: 0.3855 - val_acc: 0.8800\n",
      "Epoch 1/1\n",
      " - 244s - loss: 0.1142 - acc: 0.9616 - val_loss: 0.1808 - val_acc: 0.9330\n",
      "Epoch 1/1\n",
      " - 243s - loss: 0.1100 - acc: 0.9633 - val_loss: 0.1681 - val_acc: 0.9350\n",
      "\n",
      "\n",
      "AVERAGE TIME TAKEN BY SIMPLE NET ## 1 ## =  1.65  seconds for 1000 samples\n",
      "\n",
      "TEST ACCURACIES for Simple Net ## 1 ##\n",
      "\n",
      "Accuracy =  95.0\n",
      "\n",
      "              sensitivity  specificity      precision      f1-score\n",
      "\n",
      "Class Normal:  99.6 ,        98.67 ,        96.14 ,        97.84\n",
      "\n",
      "Class Early:   81.2 ,        99.73 ,        99.02 ,        89.23\n",
      "\n",
      "Class Late:    99.6 ,        92.4 ,        92.91 ,        96.14\n",
      "\n",
      "Average\n",
      "\n",
      "sensitivity:  93.47 , specificity:  96.93 , precision:  96.02 , f1-score:  94.4\n",
      "Epoch 1/1\n",
      " - 245s - loss: 0.3132 - acc: 0.8899 - val_loss: 0.2651 - val_acc: 0.9070\n",
      "Epoch 1/1\n",
      " - 247s - loss: 0.1903 - acc: 0.9364 - val_loss: 0.1675 - val_acc: 0.9410\n",
      "Epoch 1/1\n",
      " - 247s - loss: 0.1614 - acc: 0.9459 - val_loss: 0.2972 - val_acc: 0.8860\n",
      "Epoch 1/1\n",
      " - 246s - loss: 0.1476 - acc: 0.9511 - val_loss: 0.1853 - val_acc: 0.9500\n",
      "Epoch 1/1\n",
      " - 247s - loss: 0.1355 - acc: 0.9551 - val_loss: 0.1253 - val_acc: 0.9620\n",
      "Epoch 1/1\n",
      " - 247s - loss: 0.1297 - acc: 0.9564 - val_loss: 0.6827 - val_acc: 0.7980\n",
      "Epoch 1/1\n",
      " - 245s - loss: 0.1216 - acc: 0.9600 - val_loss: 0.1540 - val_acc: 0.9480\n",
      "Epoch 1/1\n",
      " - 239s - loss: 0.1172 - acc: 0.9614 - val_loss: 0.2206 - val_acc: 0.9200\n",
      "Epoch 1/1\n",
      " - 244s - loss: 0.1127 - acc: 0.9628 - val_loss: 0.2239 - val_acc: 0.9200\n",
      "Epoch 1/1\n",
      " - 240s - loss: 0.1085 - acc: 0.9639 - val_loss: 0.2252 - val_acc: 0.9150\n",
      "\n",
      "\n",
      "AVERAGE TIME TAKEN BY SIMPLE NET ## 2 ## =  3.67  seconds for 1000 samples\n",
      "\n",
      "TEST ACCURACIES for Simple Net ## 2 ##\n",
      "\n",
      "Accuracy =  96.2\n",
      "\n",
      "              sensitivity  specificity      precision      f1-score\n",
      "\n",
      "Class Normal:  99.6 ,        98.93 ,        96.89 ,        98.22\n",
      "\n",
      "Class Early:   86.0 ,        99.6 ,        98.62 ,        91.88\n",
      "\n",
      "Class Late:    99.6 ,        94.6 ,        94.86 ,        97.17\n",
      "\n",
      "Average\n",
      "\n",
      "sensitivity:  95.07 , specificity:  97.71 , precision:  96.79 , f1-score:  95.76\n",
      "Epoch 1/1\n",
      " - 240s - loss: 0.3508 - acc: 0.8756 - val_loss: 0.2935 - val_acc: 0.9030\n",
      "Epoch 1/1\n",
      " - 239s - loss: 0.2033 - acc: 0.9315 - val_loss: 0.1512 - val_acc: 0.9640\n",
      "Epoch 1/1\n",
      " - 244s - loss: 0.1676 - acc: 0.9445 - val_loss: 0.2119 - val_acc: 0.9240\n",
      "Epoch 1/1\n",
      " - 240s - loss: 0.1506 - acc: 0.9504 - val_loss: 0.2474 - val_acc: 0.9220\n",
      "Epoch 1/1\n",
      " - 246s - loss: 0.1409 - acc: 0.9533 - val_loss: 0.1545 - val_acc: 0.9430\n",
      "Epoch 1/1\n",
      " - 241s - loss: 0.1314 - acc: 0.9556 - val_loss: 0.1363 - val_acc: 0.9520\n",
      "Epoch 1/1\n",
      " - 241s - loss: 0.1261 - acc: 0.9584 - val_loss: 0.1977 - val_acc: 0.9310\n",
      "Epoch 1/1\n",
      " - 246s - loss: 0.1218 - acc: 0.9590 - val_loss: 0.3692 - val_acc: 0.8870\n",
      "Epoch 1/1\n",
      " - 244s - loss: 0.1145 - acc: 0.9620 - val_loss: 0.2579 - val_acc: 0.9120\n",
      "Epoch 1/1\n",
      " - 248s - loss: 0.1102 - acc: 0.9636 - val_loss: 0.2223 - val_acc: 0.9190\n",
      "\n",
      "\n",
      "AVERAGE TIME TAKEN BY SIMPLE NET ## 3 ## =  6.23  seconds for 1000 samples\n",
      "\n",
      "TEST ACCURACIES for Simple Net ## 3 ##\n",
      "\n",
      "Accuracy =  96.4\n",
      "\n",
      "              sensitivity  specificity      precision      f1-score\n",
      "\n",
      "Class Normal:  99.6 ,        98.13 ,        94.68 ,        97.08\n",
      "\n",
      "Class Early:   88.4 ,        99.33 ,        97.79 ,        92.86\n",
      "\n",
      "Class Late:    98.8 ,        96.6 ,        96.67 ,        97.73\n",
      "\n",
      "Average\n",
      "\n",
      "sensitivity:  95.6 , specificity:  98.02 , precision:  96.38 , f1-score:  95.89\n",
      "Epoch 1/1\n",
      " - 246s - loss: 0.3357 - acc: 0.8818 - val_loss: 0.3995 - val_acc: 0.8190\n",
      "Epoch 1/1\n",
      " - 244s - loss: 0.2087 - acc: 0.9290 - val_loss: 0.2512 - val_acc: 0.9120\n",
      "Epoch 1/1\n",
      " - 246s - loss: 0.1811 - acc: 0.9392 - val_loss: 0.6125 - val_acc: 0.8030\n",
      "Epoch 1/1\n",
      " - 245s - loss: 0.1638 - acc: 0.9448 - val_loss: 0.2065 - val_acc: 0.9240\n",
      "Epoch 1/1\n",
      " - 251s - loss: 0.1517 - acc: 0.9495 - val_loss: 0.4252 - val_acc: 0.8420\n",
      "Epoch 1/1\n",
      " - 250s - loss: 0.1430 - acc: 0.9526 - val_loss: 0.6942 - val_acc: 0.7910\n",
      "Epoch 1/1\n",
      " - 250s - loss: 0.1359 - acc: 0.9547 - val_loss: 0.4046 - val_acc: 0.8570\n",
      "Epoch 1/1\n",
      " - 250s - loss: 0.1310 - acc: 0.9567 - val_loss: 0.7667 - val_acc: 0.7600\n",
      "Epoch 1/1\n",
      " - 257s - loss: 0.1254 - acc: 0.9579 - val_loss: 0.3247 - val_acc: 0.8850\n",
      "Epoch 1/1\n",
      " - 257s - loss: 0.1209 - acc: 0.9599 - val_loss: 0.1646 - val_acc: 0.9420\n",
      "\n",
      "\n",
      "AVERAGE TIME TAKEN BY SIMPLE NET ## 4 ## =  9.96  seconds for 1000 samples\n",
      "\n",
      "TEST ACCURACIES for Simple Net ## 4 ##\n",
      "\n",
      "Accuracy =  94.2\n",
      "\n",
      "              sensitivity  specificity      precision      f1-score\n",
      "\n",
      "Class Normal:  100.0 ,        99.07 ,        97.28 ,        98.62\n",
      "\n",
      "Class Early:   77.2 ,        99.87 ,        99.48 ,        86.94\n",
      "\n",
      "Class Late:    99.8 ,        90.0 ,        90.89 ,        95.14\n",
      "\n",
      "Average\n",
      "\n",
      "sensitivity:  92.33 , specificity:  96.31 , precision:  95.88 , f1-score:  93.56\n",
      "Epoch 1/1\n",
      " - 254s - loss: 0.3379 - acc: 0.8796 - val_loss: 2.0472 - val_acc: 0.5100\n",
      "Epoch 1/1\n",
      " - 250s - loss: 0.2035 - acc: 0.9317 - val_loss: 0.1502 - val_acc: 0.9500\n",
      "Epoch 1/1\n",
      " - 255s - loss: 0.1716 - acc: 0.9427 - val_loss: 0.1371 - val_acc: 0.9500\n",
      "Epoch 1/1\n",
      " - 251s - loss: 0.1562 - acc: 0.9480 - val_loss: 0.1348 - val_acc: 0.9540\n",
      "Epoch 1/1\n",
      " - 255s - loss: 0.1444 - acc: 0.9523 - val_loss: 0.4068 - val_acc: 0.8440\n",
      "Epoch 1/1\n",
      " - 251s - loss: 0.1378 - acc: 0.9542 - val_loss: 0.3459 - val_acc: 0.8840\n",
      "Epoch 1/1\n",
      " - 254s - loss: 0.1316 - acc: 0.9563 - val_loss: 0.1744 - val_acc: 0.9400\n",
      "Epoch 1/1\n",
      " - 252s - loss: 0.1253 - acc: 0.9580 - val_loss: 0.5866 - val_acc: 0.8430\n",
      "Epoch 1/1\n",
      " - 255s - loss: 0.1214 - acc: 0.9598 - val_loss: 0.2712 - val_acc: 0.9080\n",
      "Epoch 1/1\n",
      " - 252s - loss: 0.1165 - acc: 0.9606 - val_loss: 0.3011 - val_acc: 0.8960\n",
      "\n",
      "\n",
      "AVERAGE TIME TAKEN BY SIMPLE NET ## 5 ## =  13.88  seconds for 1000 samples\n",
      "\n",
      "TEST ACCURACIES for Simple Net ## 5 ##\n",
      "\n",
      "Accuracy =  95.4\n",
      "\n",
      "              sensitivity  specificity      precision      f1-score\n",
      "\n",
      "Class Normal:  99.6 ,        98.0 ,        94.32 ,        96.89\n",
      "\n",
      "Class Early:   89.6 ,        98.0 ,        93.72 ,        91.62\n",
      "\n",
      "Class Late:    96.2 ,        96.8 ,        96.78 ,        96.49\n",
      "\n",
      "Average\n",
      "\n",
      "sensitivity:  95.13 , specificity:  97.6 , precision:  94.94 , f1-score:  95.0\n",
      "Epoch 1/1\n",
      " - 259s - loss: 0.3304 - acc: 0.8847 - val_loss: 0.2962 - val_acc: 0.8980\n",
      "Epoch 1/1\n",
      " - 256s - loss: 0.2045 - acc: 0.9300 - val_loss: 0.5250 - val_acc: 0.8100\n",
      "Epoch 1/1\n",
      " - 259s - loss: 0.1716 - acc: 0.9421 - val_loss: 1.0216 - val_acc: 0.6860\n",
      "Epoch 1/1\n",
      " - 256s - loss: 0.1544 - acc: 0.9487 - val_loss: 0.8168 - val_acc: 0.7720\n",
      "Epoch 1/1\n",
      " - 260s - loss: 0.1435 - acc: 0.9522 - val_loss: 0.2134 - val_acc: 0.9210\n",
      "Epoch 1/1\n",
      " - 255s - loss: 0.1350 - acc: 0.9549 - val_loss: 0.4887 - val_acc: 0.8360\n",
      "Epoch 1/1\n",
      " - 259s - loss: 0.1273 - acc: 0.9574 - val_loss: 0.2740 - val_acc: 0.8950\n",
      "Epoch 1/1\n",
      " - 256s - loss: 0.1222 - acc: 0.9592 - val_loss: 0.2251 - val_acc: 0.9260\n",
      "Epoch 1/1\n",
      " - 260s - loss: 0.1160 - acc: 0.9611 - val_loss: 0.5030 - val_acc: 0.8380\n",
      "Epoch 1/1\n",
      " - 260s - loss: 0.1133 - acc: 0.9620 - val_loss: 0.7682 - val_acc: 0.7790\n",
      "\n",
      "\n",
      "AVERAGE TIME TAKEN BY SIMPLE NET ## 6 ## =  18.49  seconds for 1000 samples\n",
      "\n",
      "TEST ACCURACIES for Simple Net ## 6 ##\n",
      "\n",
      "Accuracy =  92.6\n",
      "\n",
      "              sensitivity  specificity      precision      f1-score\n",
      "\n",
      "Class Normal:  100.0 ,        98.67 ,        96.15 ,        98.04\n",
      "\n",
      "Class Early:   70.4 ,        100.0 ,        100.0 ,        82.63\n",
      "\n",
      "Class Late:    100.0 ,        87.2 ,        88.65 ,        93.98\n",
      "\n",
      "Average\n",
      "\n",
      "sensitivity:  90.13 , specificity:  95.29 , precision:  94.94 , f1-score:  91.55\n",
      "Epoch 1/1\n",
      " - 267s - loss: 0.3335 - acc: 0.8834 - val_loss: 0.2584 - val_acc: 0.9160\n",
      "Epoch 1/1\n",
      " - 264s - loss: 0.2022 - acc: 0.9318 - val_loss: 0.3173 - val_acc: 0.8790\n",
      "Epoch 1/1\n",
      " - 260s - loss: 0.1685 - acc: 0.9438 - val_loss: 0.2953 - val_acc: 0.8930\n",
      "Epoch 1/1\n",
      " - 263s - loss: 0.1503 - acc: 0.9500 - val_loss: 0.4085 - val_acc: 0.8570\n",
      "Epoch 1/1\n",
      " - 262s - loss: 0.1392 - acc: 0.9541 - val_loss: 0.1301 - val_acc: 0.9560\n",
      "Epoch 1/1\n",
      " - 264s - loss: 0.1316 - acc: 0.9563 - val_loss: 0.3591 - val_acc: 0.8620\n",
      "Epoch 1/1\n",
      " - 264s - loss: 0.1246 - acc: 0.9579 - val_loss: 0.3434 - val_acc: 0.8750\n",
      "Epoch 1/1\n",
      " - 263s - loss: 0.1184 - acc: 0.9604 - val_loss: 0.7493 - val_acc: 0.7780\n",
      "Epoch 1/1\n",
      " - 269s - loss: 0.1137 - acc: 0.9626 - val_loss: 0.2544 - val_acc: 0.9070\n",
      "Epoch 1/1\n",
      " - 264s - loss: 0.1098 - acc: 0.9643 - val_loss: 0.3335 - val_acc: 0.8870\n",
      "\n",
      "\n",
      "AVERAGE TIME TAKEN BY SIMPLE NET ## 7 ## =  23.77  seconds for 1000 samples\n",
      "\n",
      "TEST ACCURACIES for Simple Net ## 7 ##\n",
      "\n",
      "Accuracy =  95.6\n",
      "\n",
      "              sensitivity  specificity      precision      f1-score\n",
      "\n",
      "Class Normal:  100.0 ,        98.27 ,        95.06 ,        97.47\n",
      "\n",
      "Class Early:   83.2 ,        99.73 ,        99.05 ,        90.43\n",
      "\n",
      "Class Late:    99.6 ,        94.2 ,        94.5 ,        96.98\n",
      "\n",
      "Average\n",
      "\n",
      "sensitivity:  94.27 , specificity:  97.4 , precision:  96.2 , f1-score:  94.96\n",
      "Epoch 1/1\n",
      " - 267s - loss: 0.3170 - acc: 0.8889 - val_loss: 0.4076 - val_acc: 0.8360\n",
      "Epoch 1/1\n",
      " - 265s - loss: 0.1907 - acc: 0.9355 - val_loss: 0.2686 - val_acc: 0.8990\n",
      "Epoch 1/1\n",
      " - 268s - loss: 0.1639 - acc: 0.9452 - val_loss: 0.2341 - val_acc: 0.9290\n",
      "Epoch 1/1\n",
      " - 271s - loss: 0.1488 - acc: 0.9502 - val_loss: 0.3009 - val_acc: 0.8990\n",
      "Epoch 1/1\n",
      " - 271s - loss: 0.1400 - acc: 0.9539 - val_loss: 0.1298 - val_acc: 0.9630\n",
      "Epoch 1/1\n",
      " - 271s - loss: 0.1326 - acc: 0.9556 - val_loss: 0.1557 - val_acc: 0.9480\n",
      "Epoch 1/1\n",
      " - 276s - loss: 0.1264 - acc: 0.9580 - val_loss: 0.4860 - val_acc: 0.8600\n",
      "Epoch 1/1\n",
      " - 278s - loss: 0.1206 - acc: 0.9601 - val_loss: 0.1632 - val_acc: 0.9440\n",
      "Epoch 1/1\n",
      " - 278s - loss: 0.1149 - acc: 0.9619 - val_loss: 0.2587 - val_acc: 0.9050\n",
      "Epoch 1/1\n",
      " - 277s - loss: 0.1108 - acc: 0.9632 - val_loss: 0.4016 - val_acc: 0.8690\n",
      "\n",
      "\n",
      "AVERAGE TIME TAKEN BY SIMPLE NET ## 8 ## =  29.97  seconds for 1000 samples\n",
      "\n",
      "TEST ACCURACIES for Simple Net ## 8 ##\n",
      "\n",
      "Accuracy =  96.3\n",
      "\n",
      "              sensitivity  specificity      precision      f1-score\n",
      "\n",
      "Class Normal:  99.6 ,        99.2 ,        97.65 ,        98.61\n",
      "\n",
      "Class Early:   86.8 ,        99.6 ,        98.64 ,        92.34\n",
      "\n",
      "Class Late:    99.4 ,        94.4 ,        94.67 ,        96.98\n",
      "\n",
      "Average\n",
      "\n",
      "sensitivity:  95.27 , specificity:  97.73 , precision:  96.98 , f1-score:  95.98\n",
      "Epoch 1/1\n",
      " - 278s - loss: 0.3086 - acc: 0.8917 - val_loss: 0.9536 - val_acc: 0.7250\n",
      "Epoch 1/1\n",
      " - 281s - loss: 0.1920 - acc: 0.9360 - val_loss: 0.8819 - val_acc: 0.7640\n",
      "Epoch 1/1\n",
      " - 281s - loss: 0.1597 - acc: 0.9469 - val_loss: 0.1168 - val_acc: 0.9770\n",
      "Epoch 1/1\n",
      " - 282s - loss: 0.1468 - acc: 0.9518 - val_loss: 0.2683 - val_acc: 0.9000\n",
      "Epoch 1/1\n",
      " - 281s - loss: 0.1343 - acc: 0.9553 - val_loss: 0.1632 - val_acc: 0.9420\n",
      "Epoch 1/1\n",
      " - 284s - loss: 0.1279 - acc: 0.9584 - val_loss: 0.2837 - val_acc: 0.8950\n",
      "Epoch 1/1\n",
      " - 283s - loss: 0.1213 - acc: 0.9597 - val_loss: 0.2889 - val_acc: 0.8980\n",
      "Epoch 1/1\n",
      " - 283s - loss: 0.1176 - acc: 0.9610 - val_loss: 0.3783 - val_acc: 0.8680\n",
      "Epoch 1/1\n",
      " - 282s - loss: 0.1114 - acc: 0.9633 - val_loss: 0.2561 - val_acc: 0.9110\n",
      "Epoch 1/1\n",
      " - 284s - loss: 0.1059 - acc: 0.9649 - val_loss: 0.4141 - val_acc: 0.8740\n",
      "\n",
      "\n",
      "AVERAGE TIME TAKEN BY SIMPLE NET ## 9 ## =  36.57  seconds for 1000 samples\n",
      "\n",
      "TEST ACCURACIES for Simple Net ## 9 ##\n",
      "\n",
      "Accuracy =  97.7\n",
      "\n",
      "              sensitivity  specificity      precision      f1-score\n",
      "\n",
      "Class Normal:  100.0 ,        99.07 ,        97.28 ,        98.62\n",
      "\n",
      "Class Early:   95.2 ,        98.67 ,        95.97 ,        95.58\n",
      "\n",
      "Class Late:    97.8 ,        98.8 ,        98.79 ,        98.29\n",
      "\n",
      "Average\n",
      "\n",
      "sensitivity:  97.67 , specificity:  98.84 , precision:  97.34 , f1-score:  97.5\n",
      "Epoch 1/1\n",
      " - 283s - loss: 0.3387 - acc: 0.8820 - val_loss: 0.4556 - val_acc: 0.8190\n",
      "Epoch 1/1\n",
      " - 282s - loss: 0.2069 - acc: 0.9305 - val_loss: 0.2301 - val_acc: 0.9210\n",
      "Epoch 1/1\n",
      " - 283s - loss: 0.1724 - acc: 0.9425 - val_loss: 0.5534 - val_acc: 0.8390\n",
      "Epoch 1/1\n",
      " - 283s - loss: 0.1565 - acc: 0.9479 - val_loss: 0.4493 - val_acc: 0.8540\n",
      "Epoch 1/1\n",
      " - 288s - loss: 0.1435 - acc: 0.9520 - val_loss: 0.4391 - val_acc: 0.8510\n",
      "Epoch 1/1\n",
      " - 290s - loss: 0.1352 - acc: 0.9546 - val_loss: 0.2553 - val_acc: 0.9090\n",
      "Epoch 1/1\n",
      " - 288s - loss: 0.1305 - acc: 0.9567 - val_loss: 0.6133 - val_acc: 0.7980\n",
      "Epoch 1/1\n",
      " - 289s - loss: 0.1215 - acc: 0.9594 - val_loss: 1.0589 - val_acc: 0.7390\n",
      "Epoch 1/1\n",
      " - 292s - loss: 0.1176 - acc: 0.9610 - val_loss: 0.2240 - val_acc: 0.9170\n",
      "Epoch 1/1\n",
      " - 291s - loss: 0.1121 - acc: 0.9629 - val_loss: 0.3722 - val_acc: 0.8770\n",
      "\n",
      "\n",
      "AVERAGE TIME TAKEN BY SIMPLE NET ## 10 ## =  43.2  seconds for 1000 samples\n",
      "\n",
      "TEST ACCURACIES for Simple Net ## 10 ##\n",
      "\n",
      "Accuracy =  92.1\n",
      "\n",
      "              sensitivity  specificity      precision      f1-score\n",
      "\n",
      "Class Normal:  100.0 ,        96.53 ,        90.58 ,        95.06\n",
      "\n",
      "Class Early:   70.8 ,        99.87 ,        99.44 ,        82.71\n",
      "\n",
      "Class Late:    98.8 ,        89.6 ,        90.48 ,        94.46\n",
      "\n",
      "Average\n",
      "\n",
      "sensitivity:  89.87 , specificity:  95.33 , precision:  93.5 , f1-score:  90.74\n"
     ]
    }
   ],
   "source": [
    "each_perf ={}\n",
    "for i in range(1,11):\n",
    "    img, y = shuffle(img,y)\n",
    "    img, y = shuffle(img,y)\n",
    "    img, y = shuffle(img,y)\n",
    "    train_save(i)\n",
    "    each_perf[i] = test_performance(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a>\n",
    "### 7. Performance metrics of proposed SimpleNet Model on testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_performance_average_each_model(p,i):\n",
    "    a = list(p[i][2].keys())\n",
    "    b = list(p[i][2][a[0]].keys())\n",
    "\n",
    "    s = np.zeros(7)\n",
    "    pn = 0\n",
    "    pe = 0\n",
    "    pl =0\n",
    "    fn =0\n",
    "    fe = 0\n",
    "    fl = 0\n",
    "    rn = 0\n",
    "    re = 0\n",
    "    rl = 0\n",
    "    for j in range(i,i+1):\n",
    "        s = s + p[j][0]\n",
    "        pn = pn +  p[j][2][a[0]][b[0]]\n",
    "        pe = pe +  p[j][2][a[1]][b[0]]\n",
    "        pl = pl +  p[j][2][a[2]][b[0]]\n",
    "        fn = fn + p[j][2][a[0]][b[2]]\n",
    "        fe = fe + p[j][2][a[1]][b[2]]\n",
    "        fl = fl +  p[j][2][a[2]][b[2]]\n",
    "        rn = rn +  p[j][2][a[0]][b[1]]\n",
    "        re = re +  p[j][2][a[1]][b[1]]\n",
    "        rl = rl +  p[j][2][a[2]][b[1]]\n",
    "    print(\"\\n\\n###### Metrics for Best Model (Trial \",i, \") ######\" )\n",
    "    print('\\nacc = ',round(s[0]*100,2))\n",
    "    print(\"              sensitivity  specificity      precision      f1-score\")\n",
    "    print('\\nClass Normal: ',round(s[1]*100,2), \",       \", round(s[2]*100,2), \",       \", round(pn*100,2),\",       \", round(fn*100,2))\n",
    "    print('\\nClass Early:  ',round(s[3]*100,2), \",       \", round(s[4]*100,2), \",       \", round(pe*100,2),\",       \", round(fe*100,2))\n",
    "    print('\\nClass Late:   ',round(s[5]*100,2), \",       \", round(s[6]*100,2), \",       \", round(pl*100,2),\",       \", round(fl*100,2))\n",
    "\n",
    "    print('\\n\\n##### Average Performance Metrics for Best Model (Trial ', i, ') #####')\n",
    "    avg_prec = round(p[j][2][a[5]][b[0]]*100,2)\n",
    "    avg_sens = round(np.sum([s[1]*p[j][2][a[0]][b[3]],\n",
    "                      s[3]*p[j][2][a[1]][b[3]],\n",
    "                      s[5]*p[j][2][a[2]][b[3]]])*(100/p[j][2][a[5]][b[3]]),2)\n",
    "    avg_spec = round(np.sum([s[2]*p[j][2][a[0]][b[3]],\n",
    "                      s[4]*p[j][2][a[1]][b[3]],\n",
    "                      s[6]*p[j][2][a[2]][b[3]]])*(100/p[j][2][a[5]][b[3]]),2)\n",
    "    avg_f1 = round(p[j][2][a[5]][b[2]]*100,2)\n",
    "    acc = round(s[0]*100,2)\n",
    "    print('\\nprecision: ',avg_prec,'sensitivity: ',avg_sens, \", specificity: \",avg_spec, \", f1-score: \", avg_f1)\n",
    "    return [avg_prec, avg_sens, avg_spec, avg_f1, acc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###### Metrics for Best Model (Trial 9 ) ######\n",
      "\n",
      "acc =  97.7\n",
      "              sensitivity  specificity      precision      f1-score\n",
      "\n",
      "Class Normal:  100.0 ,        99.07 ,        97.28 ,        98.62\n",
      "\n",
      "Class Early:   95.2 ,        98.67 ,        95.97 ,        95.58\n",
      "\n",
      "Class Late:    97.8 ,        98.8 ,        98.79 ,        98.29\n",
      "\n",
      "\n",
      "##### Average Performance Metrics for Best Model (Trial 9 ) #####\n",
      "\n",
      "precision:  97.7 sensitivity:  97.7 , specificity:  98.83 , f1-score:  97.7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[97.7, 97.7, 98.83, 97.7, 97.7]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_performance_average_each_model(each_perf,9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
