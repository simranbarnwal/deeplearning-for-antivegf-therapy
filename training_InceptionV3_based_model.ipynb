{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training The Transfer Learning Models\n",
    "## InceptionV3 based transfer learning technique for comparison with SimpleNet\n",
    "The notebook contains code used for training a transfer learning method using InceptionV3 model. \n",
    "The model classifies preprocessed retinal OCT scans into three categories: urgent referral, routine referral\n",
    "and normal. **5-fold cross validation** was used to present an accurate estimate of the efficacy of the model \n",
    "on unseen data. The notebooks were run on the kaggle platform for training purposes. **Since the 5-folds\n",
    "and initial weights of the deep neural net are random, the accuracies might not match with the accuracies\n",
    "given in the publication.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "* [1. Importing all modules](#1)\n",
    "* [2. Loading train and test data](#2)\n",
    "* [3. Generator Classes using Sequence class](#3)\n",
    "* [4. Functions for building and loading the transfer learning model](#4)\n",
    "* [5. Functions for training and cross-validation](#5)\n",
    "* [6. Training the model](#6)\n",
    "* [7. Performance metrics of InceptionV3 based model](#7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "### 1. Importing all modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from scipy.misc import imread\n",
    "get_ipython().magic('matplotlib inline')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import Sequence\n",
    "from cv2 import * #Import functions from OpenCV\n",
    "import cv2\n",
    "import glob\n",
    "from skimage.transform import resize\n",
    "import tensorflow as tf\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import model_from_json\n",
    "import json\n",
    "from statistics import mean\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "### 2. Loading train and test data\n",
    "\n",
    "Training data is loaded from the initial k-fold split across all the four models for accurate judgement.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X and y stores the images as arrays and the their target categories respectively\n",
    "\n",
    "X = np.genfromtxt('../input/final-paper-kfold/X.out', dtype='unicode')\n",
    "y = np.genfromtxt('../input/final-paper-kfold/y.out')\n",
    "\n",
    "#reading test images, because can't use validation generator here, as that limilts the time\n",
    "\n",
    "t_img = []\n",
    "t_y=[]\n",
    "for images in glob.glob(\"../input/no-med-filt-224/no_median_filter_224/no_median_filter_224/test/CNV/*.jpeg\"):\n",
    "    n = resize(imread(images), (224, 224,3))\n",
    "    t_img.append(n)\n",
    "    t_y.append(2)    \n",
    "    \n",
    "for images in glob.glob(\"../input/no-med-filt-224/no_median_filter_224/no_median_filter_224/test/DME/*.jpeg\"):\n",
    "    n = resize(imread(images), (224, 224,3))\n",
    "    t_img.append(n)\n",
    "    t_y.append(2)    \n",
    "    \n",
    "for images in glob.glob(\"../input/no-med-filt-224/no_median_filter_224/no_median_filter_224/test/DRUSEN/*.jpeg\"):\n",
    "    n = resize(imread(images), (224, 224,3))\n",
    "    t_img.append(n)\n",
    "    t_y.append(1)    \n",
    "    \n",
    "for images in glob.glob(\"../input/no-med-filt-224/no_median_filter_224/no_median_filter_224/test/NORMAL/*.jpeg\"):\n",
    "    n = resize(imread(images), (224, 224,3))\n",
    "    t_img.append(n)\n",
    "    t_y.append(0)    \n",
    "\n",
    "t_img = np.asarray(t_img)\n",
    "t_y = np.asarray(t_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "### 3. Generator Classes using Sequence class\n",
    "Since our training dataset is large, we would use the Sequence class to help us feed images in batches for training.\n",
    "Different generator classes are defined for training on four folds and cross-validation on the remaining fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "93cad25f972ed8e4d3edfb8a18ccaaad21157f03",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class My_Generator(Sequence):\n",
    "\n",
    "    def __init__(self, image_filenames, labels, batch_size):\n",
    "        self.image_filenames, self.labels = image_filenames, labels\n",
    "        self.batch_size = batch_size\n",
    "        self.n = len(image_filenames)\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.image_filenames) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx_min = idx*self.batch_size\n",
    "        idx_max = np.amin([((idx+1)*self.batch_size),self.n])\n",
    "        batch_x = self.image_filenames[idx_min:idx_max]\n",
    "        batch_y = self.labels[idx_min:idx_max]\n",
    "        X = np.array([\n",
    "            resize(imread(file_name), (224, 224,3))\n",
    "               for file_name in batch_x])\n",
    "        y = np.array(batch_y)\n",
    "        return X,y\n",
    "    \n",
    "class My_valid_Generator(Sequence):\n",
    "\n",
    "    def __init__(self, image_filenames, batch_size):\n",
    "        self.image_filenames = image_filenames\n",
    "        self.batch_size = batch_size\n",
    "        self.n = len(image_filenames)\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.image_filenames) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx_min = idx*self.batch_size\n",
    "        idx_max = np.amin([((idx+1)*self.batch_size),self.n])\n",
    "        batch_x = self.image_filenames[idx_min:idx_max]\n",
    "        X = np.array([\n",
    "            resize(imread(file_name), (224, 224,3))\n",
    "               for file_name in batch_x])\n",
    "        return X\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "### 4. Functions for building and loading the transfer learning model\n",
    "\n",
    "For each cross-validation build_model() builds the initial InceptionV3 based model framework whereas load_ith_model() \n",
    "loads the ith cross-validation model from memory for testing and validation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "93cad25f972ed8e4d3edfb8a18ccaaad21157f03"
   },
   "outputs": [],
   "source": [
    "# for the first 22 epochs\n",
    "\n",
    "def build_model():\n",
    "    #load InceptionV3 without dense layer and with theano dim ordering\n",
    "    base_model = InceptionV3(weights='../input/inceptionv3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top = False, input_shape = (224,224,3))\n",
    "    for layer in base_model.layers:\n",
    "        # batch-normalization layers were trained on previous imagenet images\n",
    "        # so we are training batch-normalization layers again for our specific dataset\n",
    "        if layer.name[0:10]!='batch_norm':\n",
    "            layer.trainable = False \n",
    "    num_classes = 3\n",
    "\n",
    "    x = Flatten()(base_model.output)\n",
    "    predictions = Dense(num_classes, activation = 'softmax')(x)\n",
    "\n",
    "    #create graph of your new model\n",
    "    model = Model(input = base_model.input, output = predictions)\n",
    "\n",
    "    #compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_ith_model(i):\n",
    "    json_file = open('model-'+str(i)+'.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    model.load_weights('model-'+str(i)+'.h5')\n",
    "\n",
    "    #compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for the next 28 epochs\n",
    "\n",
    "def build_model_old():\n",
    "    json_file = open('../input/model-'+str(i)+'.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    model.load_weights('../input/model-'+str(i)+'.h5')\n",
    "\n",
    "    #compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_save_validate_old(i):\n",
    "    batch_size = 64\n",
    "    train_index = np.genfromtxt('../input/final-paper-kfold/train_index-'+str(i)+'.out').astype(int)\n",
    "    test_index = np.genfromtxt('../input/final-paper-kfold/test_index-'+str(i)+'.out').astype(int)\n",
    "    trainData = X[train_index]\n",
    "    testData = X[test_index]\n",
    "    trainLabels = y[train_index]\n",
    "    testLabels = y[test_index]\n",
    "\n",
    "    trainGenerator = My_Generator(trainData,trainLabels,batch_size)\n",
    "    valGenerator = My_valid_Generator(testData,400)\n",
    "    \n",
    "    model = build_model_old()\n",
    "    \n",
    "    model.fit_generator(\n",
    "            generator = trainGenerator,\n",
    "            steps_per_epoch=(len(trainData)//batch_size),\n",
    "            epochs=28, verbose = 2, class_weight = [0.70596402, 4.19022748, 0.74357918])\n",
    "    \n",
    "    model_json = model.to_json()\n",
    "    with open('model-'+str(i)+'.json', \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights('model-'+str(i)+'.h5')\n",
    "    \n",
    "    t_y = np.argmax(testLabels,axis=1)    \n",
    "    ans = np.argmax(model.predict_generator(valGenerator),axis =1)\n",
    "    \n",
    "    # performance metrics  \n",
    "    return performance_metrics(t_y,ans)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "### 5. Functions for training and cross-validation\n",
    "For each cross-validation i, train_save_validate() trains the model, saves model-i and saves the validation performance\n",
    "metrics on validation fold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_save_validate(i):\n",
    "    batch_size = 64\n",
    "    train_index = np.genfromtxt('../input/final-paper-kfold/train_index-'+str(i)+'.out').astype(int)\n",
    "    test_index = np.genfromtxt('../input/final-paper-kfold/test_index-'+str(i)+'.out').astype(int)\n",
    "    trainData = X[train_index]\n",
    "    testData = X[test_index]\n",
    "    trainLabels = y[train_index]\n",
    "    testLabels = y[test_index]\n",
    "\n",
    "    trainGenerator = My_Generator(trainData,trainLabels,batch_size)\n",
    "    valGenerator = My_valid_Generator(testData,400)\n",
    "    \n",
    "    model = build_model()\n",
    "    if i ==1:\n",
    "        model.summary()\n",
    "        \n",
    "    model.fit_generator(\n",
    "            generator = trainGenerator,\n",
    "            steps_per_epoch=(len(trainData)//batch_size),\n",
    "            epochs=22, verbose = 2, class_weight = [0.70596402, 4.19022748, 0.74357918])\n",
    "    \n",
    "    model_json = model.to_json()\n",
    "    with open('model-'+str(i)+'.json', \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights('model-'+str(i)+'.h5')\n",
    "    \n",
    "    t_y = np.argmax(testLabels,axis=1)    \n",
    "    ans = np.argmax(model.predict_generator(valGenerator),axis =1)\n",
    "    \n",
    "    # performance metrics  \n",
    "    return performance_metrics(t_y,ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**perfromance_metrics()** derives all performance measures from the confusion matrix whereas **print_performance_average_each_model()** prints the validation metrics in a readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_metrics(test_y,ans):\n",
    "    acc = accuracy_score(test_y,ans)\n",
    "    print('Accuracy = ',acc)\n",
    "    target_names = ['CLass Normal', 'CLass Early', 'Class Late']\n",
    "    \n",
    "    # computing all metrics via the confusion matrix\n",
    "    cm = confusion_matrix(test_y, ans) \n",
    "    sens0 = cm[0,0]/(cm[0,0]+cm[0,1]+cm[0,2])\n",
    "    spec0 = (cm[1,1]+cm[1,2]+cm[2,1] +cm[2,2])/((cm[1,1]+cm[1,2]+cm[2,1] +cm[2,2])+(cm[1,0]+cm[2,0]))\n",
    "\n",
    "    sens1 = cm[1,1]/(cm[1,0]+cm[1,1]+cm[1,2])\n",
    "    spec1 = (cm[0,0]+cm[2,0]+cm[0,2] +cm[2,2])/((cm[0,0]+cm[2,0]+cm[0,2] +cm[2,2])+(cm[0,1]+cm[2,1]))\n",
    "\n",
    "    sens2 = cm[2,2]/(cm[2,0]+cm[2,1]+cm[2,2])\n",
    "    spec2 = (cm[0,0]+cm[0,1]+cm[1,0] +cm[1,1])/((cm[0,0]+cm[0,1]+cm[1,0] +cm[1,1])+(cm[0,2]+cm[1,2]))\n",
    "  \n",
    "    rep=classification_report(test_y, ans, target_names=target_names, digits = 4, labels=range(0,3),output_dict=True)\n",
    "    return [acc,sens0,spec0,sens1,spec1,sens2,spec2],cm,rep\n",
    "\n",
    "# method for printing performance \n",
    "def print_performance_average_each_model(p,i):\n",
    "    a = list(p[i][2].keys())\n",
    "    b = list(p[i][2][a[0]].keys())\n",
    "\n",
    "    s = np.zeros(7)\n",
    "    pn = 0\n",
    "    pe = 0\n",
    "    pl =0\n",
    "    fn =0\n",
    "    fe = 0\n",
    "    fl = 0\n",
    "    rn = 0\n",
    "    re = 0\n",
    "    rl = 0\n",
    "    for j in range(i,i+1):\n",
    "        s = s + p[j][0]\n",
    "        pn = pn +  p[j][2][a[0]][b[0]]\n",
    "        pe = pe +  p[j][2][a[1]][b[0]]\n",
    "        pl = pl +  p[j][2][a[2]][b[0]]\n",
    "        fn = fn + p[j][2][a[0]][b[2]]\n",
    "        fe = fe + p[j][2][a[1]][b[2]]\n",
    "        fl = fl +  p[j][2][a[2]][b[2]]\n",
    "        rn = rn +  p[j][2][a[0]][b[1]]\n",
    "        re = re +  p[j][2][a[1]][b[1]]\n",
    "        rl = rl +  p[j][2][a[2]][b[1]]\n",
    "    print(\"\\n\\n###### Metrics for Fold \",i, \" ######\" )\n",
    "    print('\\nacc = ',round(s[0]*100,2))\n",
    "    print(\"              sensitivity  specificity      precision      f1-score\")\n",
    "    print('\\nClass Normal: ',round(s[1]*100,2), \",       \", round(s[2]*100,2), \",       \", round(pn*100,2),\",       \", round(fn*100,2))\n",
    "    print('\\nClass Early:  ',round(s[3]*100,2), \",       \", round(s[4]*100,2), \",       \", round(pe*100,2),\",       \", round(fe*100,2))\n",
    "    print('\\nClass Late:   ',round(s[5]*100,2), \",       \", round(s[6]*100,2), \",       \", round(pl*100,2),\",       \", round(fl*100,2))\n",
    "\n",
    "    print('\\n\\n##### Average Performance Metrics for Fold ', i, ' #####')\n",
    "    avg_prec = round(p[j][2][a[5]][b[0]]*100,2)\n",
    "    avg_sens = round(np.sum([s[1]*p[j][2][a[0]][b[3]],\n",
    "                      s[3]*p[j][2][a[1]][b[3]],\n",
    "                      s[5]*p[j][2][a[2]][b[3]]])*(100/p[j][2][a[5]][b[3]]),2)\n",
    "    avg_spec = round(np.sum([s[2]*p[j][2][a[0]][b[3]],\n",
    "                      s[4]*p[j][2][a[1]][b[3]],\n",
    "                      s[6]*p[j][2][a[2]][b[3]]])*(100/p[j][2][a[5]][b[3]]),2)\n",
    "    avg_f1 = round(p[j][2][a[5]][b[2]]*100,2)\n",
    "    acc = round(s[0]*100,2)\n",
    "    print('\\nprecision: ',avg_prec,'sensitivity: ',avg_sens, \", specificity: \",avg_spec, \", f1-score: \", avg_f1)\n",
    "    return [avg_prec, avg_sens, avg_spec, avg_f1, acc]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <a id=\"6\"></a>\n",
    "### 6. Training the InceptionV3 model\n",
    "This cell is not executed in this notebook as each training will yield different results. Kindly send me an email if you need the trained weights used in the publication.\n",
    "\n",
    "Each cell executes a part of the cross-validation because each cell in kaggle had a maximum running time limit. This notebook shows the first 22 epochs of execution, the next 28 epochs were run on a separate notebook (with adequately modified functions to load and train the model) and is not shown due to redundancy. Kindly send me an email if you need the other notebook. If you have the computing power to run it all in one go, please change of epochs from 22 to 50 in the train_save_validate(i) method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== K Fold Validation step => 1/5 =======\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:53: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 111, 111, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 111, 111, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 111, 111, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 109, 109, 32) 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 109, 109, 32) 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 109, 109, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 109, 109, 64) 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 109, 109, 64) 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 109, 109, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 54, 54, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 54, 54, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 54, 54, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 52, 52, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 52, 52, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 52, 52, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 25, 25, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 25, 25, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 25, 25, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 25, 25, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 25, 25, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 25, 25, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 25, 25, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 25, 25, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 25, 25, 32)   6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 25, 25, 64)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 25, 25, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 25, 25, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 25, 25, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 25, 25, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 25, 25, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 25, 25, 64)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 25, 25, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 25, 25, 96)   55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 25, 25, 48)   144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 25, 25, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 25, 25, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 25, 25, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 25, 25, 64)   76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 25, 25, 96)   82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 25, 25, 64)   16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 25, 25, 64)   192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 25, 25, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 25, 25, 96)   288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 25, 25, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 25, 25, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 25, 25, 96)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 25, 25, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 25, 25, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 25, 25, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 25, 25, 96)   55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 25, 25, 48)   144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 25, 25, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 25, 25, 48)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 25, 25, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 25, 25, 64)   76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 25, 25, 96)   82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 25, 25, 64)   18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 25, 25, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 25, 25, 96)   288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 25, 25, 64)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 25, 25, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 25, 25, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 25, 25, 96)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 25, 25, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 25, 25, 64)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 25, 25, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 25, 25, 96)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 25, 25, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 25, 25, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 12, 12, 96)   82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 12, 12, 384)  1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 12, 12, 96)   288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 12, 12, 384)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 12, 12, 96)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 12, 12, 128)  114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 12, 12, 128)  114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 12, 12, 128)  384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 12, 12, 128)  384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 12, 12, 128)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 12, 12, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 12, 12, 192)  172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 12, 12, 192)  172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 12, 12, 192)  576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 12, 12, 192)  576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 12, 12, 192)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 12, 12, 192)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 12, 12, 160)  179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 12, 12, 160)  179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 12, 12, 160)  480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 12, 12, 160)  480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 12, 12, 160)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 12, 12, 160)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 12, 12, 192)  215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 12, 12, 192)  215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 12, 12, 192)  576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 12, 12, 192)  576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 12, 12, 192)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 12, 12, 192)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 12, 12, 160)  179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 12, 12, 160)  179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 12, 12, 160)  480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 12, 12, 160)  480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 12, 12, 160)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 12, 12, 160)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 12, 12, 192)  215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 12, 12, 192)  215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 12, 12, 192)  576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 12, 12, 192)  576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 12, 12, 192)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 12, 12, 192)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 12, 12, 192)  258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 12, 12, 192)  258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 12, 12, 192)  258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 12, 12, 192)  576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 12, 12, 192)  576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 12, 12, 192)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 12, 12, 192)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 5, 5, 320)    552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 5, 5, 192)    331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 5, 5, 320)    960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 5, 5, 192)    576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 5, 5, 320)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 5, 5, 192)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 5, 5, 448)    1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 5, 5, 448)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 5, 5, 384)    1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 5, 5, 384)    1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 5, 5, 384)    1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 5, 5, 320)    960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 5, 5, 384)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 5, 5, 384)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 5, 5, 192)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 5, 5, 320)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 5, 5, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 5, 5, 448)    1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 5, 5, 448)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 5, 5, 384)    1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 5, 5, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 5, 5, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 5, 5, 384)    1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 5, 5, 384)    1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 5, 5, 320)    960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 5, 5, 384)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 5, 5, 384)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 5, 5, 192)    576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 5, 5, 320)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 5, 5, 768)    0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 5, 5, 192)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 51200)        0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3)            153603      flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 21,956,387\n",
      "Trainable params: 170,819\n",
      "Non-trainable params: 21,785,568\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/22\n",
      " - 1457s - loss: 1.5185 - acc: 0.8617\n",
      "Epoch 2/22\n",
      " - 1285s - loss: 1.4085 - acc: 0.8959\n",
      "Epoch 3/22\n",
      " - 1242s - loss: 1.3654 - acc: 0.9041\n",
      "Epoch 4/22\n",
      " - 1227s - loss: 1.3823 - acc: 0.9050\n",
      "Epoch 5/22\n",
      " - 1241s - loss: 1.3379 - acc: 0.9115\n",
      "Epoch 6/22\n",
      " - 1252s - loss: 1.3337 - acc: 0.9128\n",
      "Epoch 7/22\n",
      " - 1245s - loss: 1.3208 - acc: 0.9145\n",
      "Epoch 8/22\n",
      " - 1260s - loss: 1.3312 - acc: 0.9137\n",
      "Epoch 9/22\n",
      " - 1307s - loss: 1.3239 - acc: 0.9154\n",
      "Epoch 10/22\n",
      " - 1279s - loss: 1.3336 - acc: 0.9147\n",
      "Epoch 11/22\n",
      " - 1300s - loss: 1.3203 - acc: 0.9161\n",
      "Epoch 12/22\n",
      " - 1311s - loss: 1.3193 - acc: 0.9165\n",
      "Epoch 13/22\n",
      " - 1346s - loss: 1.3117 - acc: 0.9170\n",
      "Epoch 14/22\n",
      " - 1303s - loss: 1.3175 - acc: 0.9171\n",
      "Epoch 15/22\n",
      " - 1315s - loss: 1.3194 - acc: 0.9169\n",
      "Epoch 16/22\n",
      " - 1310s - loss: 1.3151 - acc: 0.9171\n",
      "Epoch 17/22\n",
      " - 1357s - loss: 1.3145 - acc: 0.9173\n",
      "Epoch 18/22\n",
      " - 1322s - loss: 1.3160 - acc: 0.9176\n",
      "Epoch 19/22\n",
      " - 1321s - loss: 1.3075 - acc: 0.9179\n",
      "Epoch 20/22\n",
      " - 1324s - loss: 1.3321 - acc: 0.9160\n",
      "Epoch 21/22\n",
      " - 1354s - loss: 1.3135 - acc: 0.9176\n",
      "Epoch 22/22\n",
      " - 1326s - loss: 1.3185 - acc: 0.9173\n",
      "Accuracy =  0.9052257409288155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "valid_perf = {}\n",
    "\n",
    "# the first 22 epochs\n",
    "for i in range(1,2):\n",
    "    print(\"\\n====== K Fold Validation step => %d/%d =======\" % (i,5))\n",
    "    \n",
    "    valid_perf[i]= train_save_validate(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== K Fold Validation step => 2/5 =======\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:53: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22\n",
      " - 1107s - loss: 1.5312 - acc: 0.8613\n",
      "Epoch 2/22\n",
      " - 1022s - loss: 1.4100 - acc: 0.8941\n",
      "Epoch 3/22\n",
      " - 1010s - loss: 1.3560 - acc: 0.9049\n",
      "Epoch 4/22\n",
      " - 1019s - loss: 1.3467 - acc: 0.9081\n",
      "Epoch 5/22\n",
      " - 1054s - loss: 1.3277 - acc: 0.9120\n",
      "Epoch 6/22\n",
      " - 1017s - loss: 1.3375 - acc: 0.9118\n",
      "Epoch 7/22\n",
      " - 1031s - loss: 1.3210 - acc: 0.9148\n",
      "Epoch 8/22\n",
      " - 1022s - loss: 1.3168 - acc: 0.9154\n",
      "Epoch 9/22\n",
      " - 1041s - loss: 1.3252 - acc: 0.9147\n",
      "Epoch 10/22\n",
      " - 1017s - loss: 1.3228 - acc: 0.9152\n",
      "Epoch 11/22\n",
      " - 1014s - loss: 1.3179 - acc: 0.9162\n",
      "Epoch 12/22\n",
      " - 1008s - loss: 1.3283 - acc: 0.9152\n",
      "Epoch 13/22\n",
      " - 1051s - loss: 1.3195 - acc: 0.9164\n",
      "Epoch 14/22\n",
      " - 1020s - loss: 1.3215 - acc: 0.9160\n",
      "Epoch 15/22\n",
      " - 1022s - loss: 1.3063 - acc: 0.9177\n",
      "Epoch 16/22\n",
      " - 1014s - loss: 1.3320 - acc: 0.9158\n",
      "Epoch 17/22\n",
      " - 1037s - loss: 1.3068 - acc: 0.9177\n",
      "Epoch 18/22\n",
      " - 1009s - loss: 1.3149 - acc: 0.9176\n",
      "Epoch 19/22\n",
      " - 1004s - loss: 1.3136 - acc: 0.9173\n",
      "Epoch 20/22\n",
      " - 1000s - loss: 1.3143 - acc: 0.9173\n",
      "Epoch 21/22\n",
      " - 1046s - loss: 1.3178 - acc: 0.9173\n",
      "Epoch 22/22\n",
      " - 1001s - loss: 1.3126 - acc: 0.9176\n",
      "Accuracy =  0.9032406979964915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# fold 2 first 22 epochs\n",
    "for i in range(2,3):\n",
    "    print(\"\\n====== K Fold Validation step => %d/%d =======\" % (i,5))\n",
    "    \n",
    "    valid_perf[i]= train_save_validate(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== K Fold Validation step => 3/5 =======\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:53: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22\n",
      " - 1049s - loss: 1.5195 - acc: 0.8631\n",
      "Epoch 2/22\n",
      " - 986s - loss: 1.4105 - acc: 0.8949\n",
      "Epoch 3/22\n",
      " - 978s - loss: 1.3637 - acc: 0.9043\n",
      "Epoch 4/22\n",
      " - 974s - loss: 1.3368 - acc: 0.9097\n",
      "Epoch 5/22\n",
      " - 1010s - loss: 1.3299 - acc: 0.9110\n",
      "Epoch 6/22\n",
      " - 977s - loss: 1.3349 - acc: 0.9121\n",
      "Epoch 7/22\n",
      " - 971s - loss: 1.3274 - acc: 0.9141\n",
      "Epoch 8/22\n",
      " - 972s - loss: 1.3243 - acc: 0.9144\n",
      "Epoch 9/22\n",
      " - 1010s - loss: 1.3387 - acc: 0.9136\n",
      "Epoch 10/22\n",
      " - 975s - loss: 1.3201 - acc: 0.9158\n",
      "Epoch 11/22\n",
      " - 972s - loss: 1.3143 - acc: 0.9166\n",
      "Epoch 12/22\n",
      " - 969s - loss: 1.3270 - acc: 0.9155\n",
      "Epoch 13/22\n",
      " - 1008s - loss: 1.3554 - acc: 0.9131\n",
      "Epoch 14/22\n",
      " - 977s - loss: 1.3332 - acc: 0.9152\n",
      "Epoch 15/22\n",
      " - 978s - loss: 1.3331 - acc: 0.9157\n",
      "Epoch 16/22\n",
      " - 969s - loss: 1.3174 - acc: 0.9167\n",
      "Epoch 17/22\n",
      " - 1009s - loss: 1.3259 - acc: 0.9165\n",
      "Epoch 18/22\n",
      " - 977s - loss: 1.3126 - acc: 0.9177\n",
      "Epoch 19/22\n",
      " - 976s - loss: 1.3133 - acc: 0.9175\n",
      "Epoch 20/22\n",
      " - 970s - loss: 1.3215 - acc: 0.9170\n",
      "Epoch 21/22\n",
      " - 1013s - loss: 1.3145 - acc: 0.9177\n",
      "Epoch 22/22\n",
      " - 978s - loss: 1.3169 - acc: 0.9175\n",
      "Accuracy =  0.90019388791432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# fold 3 first 22 epochs\n",
    "\n",
    "for i in range(3,4):\n",
    "    print(\"\\n====== K Fold Validation step => %d/%d =======\" % (i,5))\n",
    "    \n",
    "    train_save_validate(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== K Fold Validation step => 3/5 =======\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/28\n",
      " - 1071s - loss: 1.3181 - acc: 0.9174\n",
      "Epoch 2/28\n",
      " - 1006s - loss: 1.3188 - acc: 0.9174\n",
      "Epoch 3/28\n",
      " - 1014s - loss: 1.3219 - acc: 0.9172\n",
      "Epoch 4/28\n",
      " - 1010s - loss: 1.3175 - acc: 0.9175\n",
      "Epoch 5/28\n",
      " - 1048s - loss: 1.3127 - acc: 0.9180\n",
      "Epoch 6/28\n",
      " - 1003s - loss: 1.3148 - acc: 0.9178\n",
      "Epoch 7/28\n",
      " - 1004s - loss: 1.3094 - acc: 0.9181\n",
      "Epoch 8/28\n",
      " - 1007s - loss: 1.3116 - acc: 0.9179\n",
      "Epoch 9/28\n",
      " - 1045s - loss: 1.3150 - acc: 0.9177\n",
      "Epoch 10/28\n",
      " - 1004s - loss: 1.3143 - acc: 0.9178\n",
      "Epoch 11/28\n",
      " - 1007s - loss: 1.3116 - acc: 0.9182\n",
      "Epoch 12/28\n",
      " - 1006s - loss: 1.3167 - acc: 0.9177\n",
      "Epoch 13/28\n",
      " - 1039s - loss: 1.3126 - acc: 0.9181\n",
      "Epoch 14/28\n",
      " - 1015s - loss: 1.3097 - acc: 0.9181\n",
      "Epoch 15/28\n",
      " - 999s - loss: 1.3163 - acc: 0.9179\n",
      "Epoch 16/28\n",
      " - 1008s - loss: 1.3154 - acc: 0.9179\n",
      "Epoch 17/28\n",
      " - 1043s - loss: 1.3021 - acc: 0.9188\n",
      "Epoch 18/28\n",
      " - 1007s - loss: 1.3099 - acc: 0.9183\n",
      "Epoch 19/28\n",
      " - 990s - loss: 1.3174 - acc: 0.9178\n",
      "Epoch 20/28\n",
      " - 1005s - loss: 1.3115 - acc: 0.9182\n",
      "Epoch 21/28\n",
      " - 1052s - loss: 1.3109 - acc: 0.9183\n",
      "Epoch 22/28\n",
      " - 1008s - loss: 1.3103 - acc: 0.9183\n",
      "Epoch 23/28\n",
      " - 993s - loss: 1.3114 - acc: 0.9182\n",
      "Epoch 24/28\n",
      " - 1019s - loss: 1.3096 - acc: 0.9184\n",
      "Epoch 25/28\n",
      " - 1055s - loss: 1.3138 - acc: 0.9181\n",
      "Epoch 26/28\n",
      " - 998s - loss: 1.3090 - acc: 0.9184\n",
      "Epoch 27/28\n",
      " - 995s - loss: 1.3144 - acc: 0.9181\n",
      "Epoch 28/28\n",
      " - 1007s - loss: 1.3034 - acc: 0.9187\n",
      "Accuracy =  0.9056412150309298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# fold 3 next 28 epochs\n",
    "for i in range(3,4):\n",
    "    print(\"\\n====== K Fold Validation step => %d/%d =======\" % (i,5))\n",
    "    \n",
    "    valid_perf[i]= train_save_validate_old(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== K Fold Validation step => 4/5 =======\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:53: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22\n",
      " - 1028s - loss: 1.5136 - acc: 0.8636\n",
      "Epoch 2/22\n",
      " - 964s - loss: 1.4179 - acc: 0.8952\n",
      "Epoch 3/22\n",
      " - 947s - loss: 1.3713 - acc: 0.9042\n",
      "Epoch 4/22\n",
      " - 933s - loss: 1.3481 - acc: 0.9092\n",
      "Epoch 5/22\n",
      " - 962s - loss: 1.3338 - acc: 0.9120\n",
      "Epoch 6/22\n",
      " - 934s - loss: 1.3336 - acc: 0.9128\n",
      "Epoch 7/22\n",
      " - 926s - loss: 1.3433 - acc: 0.9124\n",
      "Epoch 8/22\n",
      " - 925s - loss: 1.3293 - acc: 0.9146\n",
      "Epoch 9/22\n",
      " - 957s - loss: 1.3239 - acc: 0.9154\n",
      "Epoch 10/22\n",
      " - 926s - loss: 1.3248 - acc: 0.9158\n",
      "Epoch 11/22\n",
      " - 930s - loss: 1.3236 - acc: 0.9156\n",
      "Epoch 12/22\n",
      " - 922s - loss: 1.3290 - acc: 0.9156\n",
      "Epoch 13/22\n",
      " - 953s - loss: 1.3304 - acc: 0.9156\n",
      "Epoch 14/22\n",
      " - 928s - loss: 1.3277 - acc: 0.9161\n",
      "Epoch 15/22\n",
      " - 928s - loss: 1.3177 - acc: 0.9170\n",
      "Epoch 16/22\n",
      " - 928s - loss: 1.3174 - acc: 0.9169\n",
      "Epoch 17/22\n",
      " - 956s - loss: 1.3164 - acc: 0.9172\n",
      "Epoch 18/22\n",
      " - 926s - loss: 1.3213 - acc: 0.9169\n",
      "Epoch 19/22\n",
      " - 930s - loss: 1.3289 - acc: 0.9162\n",
      "Epoch 20/22\n",
      " - 928s - loss: 1.3191 - acc: 0.9171\n",
      "Epoch 21/22\n",
      " - 951s - loss: 1.3186 - acc: 0.9174\n",
      "Epoch 22/22\n",
      " - 931s - loss: 1.3148 - acc: 0.9176\n",
      "Accuracy =  0.894054103960853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# fold 4 first 22 epochs\n",
    "\n",
    "for i in range(4,5):\n",
    "    print(\"\\n====== K Fold Validation step => %d/%d =======\" % (i,5))\n",
    "    \n",
    "    train_save_validate(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== K Fold Validation step => 4/5 =======\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/28\n",
      " - 1053s - loss: 1.3186 - acc: 0.9174\n",
      "Epoch 2/28\n",
      " - 1002s - loss: 1.3128 - acc: 0.9179\n",
      "Epoch 3/28\n",
      " - 1004s - loss: 1.3171 - acc: 0.9175\n",
      "Epoch 4/28\n",
      " - 1000s - loss: 1.3182 - acc: 0.9174\n",
      "Epoch 5/28\n",
      " - 1040s - loss: 1.3276 - acc: 0.9169\n",
      "Epoch 6/28\n",
      " - 1017s - loss: 1.3203 - acc: 0.9173\n",
      "Epoch 7/28\n",
      " - 995s - loss: 1.3137 - acc: 0.9181\n",
      "Epoch 8/28\n",
      " - 1005s - loss: 1.3075 - acc: 0.9185\n",
      "Epoch 9/28\n",
      " - 1041s - loss: 1.3264 - acc: 0.9171\n",
      "Epoch 10/28\n",
      " - 998s - loss: 1.3154 - acc: 0.9180\n",
      "Epoch 11/28\n",
      " - 1001s - loss: 1.3204 - acc: 0.9174\n",
      "Epoch 12/28\n",
      " - 994s - loss: 1.3174 - acc: 0.9177\n",
      "Epoch 13/28\n",
      " - 1033s - loss: 1.3159 - acc: 0.9179\n",
      "Epoch 14/28\n",
      " - 997s - loss: 1.3214 - acc: 0.9176\n",
      "Epoch 15/28\n",
      " - 1028s - loss: 1.3174 - acc: 0.9177\n",
      "Epoch 16/28\n",
      " - 1021s - loss: 1.3135 - acc: 0.9179\n",
      "Epoch 17/28\n",
      " - 1064s - loss: 1.3179 - acc: 0.9178\n",
      "Epoch 18/28\n",
      " - 1029s - loss: 1.3159 - acc: 0.9179\n",
      "Epoch 19/28\n",
      " - 1017s - loss: 1.3214 - acc: 0.9177\n",
      "Epoch 20/28\n",
      " - 1019s - loss: 1.3078 - acc: 0.9184\n",
      "Epoch 21/28\n",
      " - 1059s - loss: 1.3103 - acc: 0.9183\n",
      "Epoch 22/28\n",
      " - 1025s - loss: 1.3127 - acc: 0.9182\n",
      "Epoch 23/28\n",
      " - 1027s - loss: 1.3126 - acc: 0.9181\n",
      "Epoch 24/28\n",
      " - 1027s - loss: 1.3062 - acc: 0.9187\n",
      "Epoch 25/28\n",
      " - 1065s - loss: 1.3187 - acc: 0.9178\n",
      "Epoch 26/28\n",
      " - 1020s - loss: 1.3113 - acc: 0.9183\n",
      "Epoch 27/28\n",
      " - 1019s - loss: 1.3268 - acc: 0.9172\n",
      "Epoch 28/28\n",
      " - 1020s - loss: 1.3192 - acc: 0.9177\n",
      "Accuracy =  0.9069338011263964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# fold 4 next 28 epochs\n",
    "\n",
    "for i in range(4,5):\n",
    "    print(\"\\n====== K Fold Validation step => %d/%d =======\" % (i,5))\n",
    "    \n",
    "    valid_perf[i]= train_save_validate_old(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== K Fold Validation step => 5/5 =======\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:53: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22\n",
      " - 1129s - loss: 1.5045 - acc: 0.8632\n",
      "Epoch 2/22\n",
      " - 1026s - loss: 1.4128 - acc: 0.8942\n",
      "Epoch 3/22\n",
      " - 1023s - loss: 1.3668 - acc: 0.9044\n",
      "Epoch 4/22\n",
      " - 1014s - loss: 1.3414 - acc: 0.9092\n",
      "Epoch 5/22\n",
      " - 1096s - loss: 1.3231 - acc: 0.9127\n",
      "Epoch 6/22\n",
      " - 1067s - loss: 1.3193 - acc: 0.9138\n",
      "Epoch 7/22\n",
      " - 1039s - loss: 1.3175 - acc: 0.9143\n",
      "Epoch 8/22\n",
      " - 1034s - loss: 1.3159 - acc: 0.9152\n",
      "Epoch 9/22\n",
      " - 1073s - loss: 1.3163 - acc: 0.9157\n",
      "Epoch 10/22\n",
      " - 1025s - loss: 1.3172 - acc: 0.9158\n",
      "Epoch 11/22\n",
      " - 1028s - loss: 1.3092 - acc: 0.9167\n",
      "Epoch 12/22\n",
      " - 1029s - loss: 1.3118 - acc: 0.9166\n",
      "Epoch 13/22\n",
      " - 1061s - loss: 1.3095 - acc: 0.9170\n",
      "Epoch 14/22\n",
      " - 1025s - loss: 1.3044 - acc: 0.9178\n",
      "Epoch 15/22\n",
      " - 1007s - loss: 1.3134 - acc: 0.9172\n",
      "Epoch 16/22\n",
      " - 1020s - loss: 1.3277 - acc: 0.9157\n",
      "Epoch 17/22\n",
      " - 1056s - loss: 1.3483 - acc: 0.9139\n",
      "Epoch 18/22\n",
      " - 1016s - loss: 1.3387 - acc: 0.9152\n",
      "Epoch 19/22\n",
      " - 1019s - loss: 1.3268 - acc: 0.9164\n",
      "Epoch 20/22\n",
      " - 1031s - loss: 1.3184 - acc: 0.9172\n",
      "Epoch 21/22\n",
      " - 1061s - loss: 1.3145 - acc: 0.9175\n",
      "Epoch 22/22\n",
      " - 1017s - loss: 1.3130 - acc: 0.9179\n",
      "Accuracy =  0.9020820830063248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# fold 5 first 22 epochs\n",
    "\n",
    "for i in range(5,6):\n",
    "    print(\"\\n====== K Fold Validation step => %d/%d =======\" % (i,5))\n",
    "    \n",
    "    valid_perf[i] = train_save_validate(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a>\n",
    "### 7. Performance metrics of InceptionV3 based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###### Metrics for Fold  1  ######\n",
      "\n",
      "acc =  90.52\n",
      "              sensitivity  specificity      precision      f1-score\n",
      "\n",
      "Class Normal:  98.83 ,        93.94 ,        93.49 ,        96.08\n",
      "\n",
      "Class Early:   0.0 ,        100.0 ,        0.0 ,        0.0\n",
      "\n",
      "Class Late:    97.73 ,        88.57 ,        87.62 ,        92.4\n",
      "\n",
      "\n",
      "##### Average Performance Metrics for Fold  1  #####\n",
      "\n",
      "precision:  83.45 sensitivity:  90.52 , specificity:  91.99 , f1-score:  86.82\n",
      "\n",
      "\n",
      "###### Metrics for Fold  2  ######\n",
      "\n",
      "acc =  90.32\n",
      "              sensitivity  specificity      precision      f1-score\n",
      "\n",
      "Class Normal:  97.81 ,        94.82 ,        94.51 ,        96.13\n",
      "\n",
      "Class Early:   0.0 ,        100.0 ,        0.0 ,        0.0\n",
      "\n",
      "Class Late:    98.51 ,        87.48 ,        86.25 ,        91.97\n",
      "\n",
      "\n",
      "##### Average Performance Metrics for Fold  2  #####\n",
      "\n",
      "precision:  83.31 sensitivity:  90.32 , specificity:  91.98 , f1-score:  86.62\n",
      "\n",
      "\n",
      "###### Metrics for Fold  3  ######\n",
      "\n",
      "acc =  90.56\n",
      "              sensitivity  specificity      precision      f1-score\n",
      "\n",
      "Class Normal:  99.12 ,        92.97 ,        92.7 ,        95.81\n",
      "\n",
      "Class Early:   0.0 ,        100.0 ,        0.0 ,        0.0\n",
      "\n",
      "Class Late:    97.62 ,        89.63 ,        88.37 ,        92.76\n",
      "\n",
      "\n",
      "##### Average Performance Metrics for Fold  3  #####\n",
      "\n",
      "precision:  83.39 sensitivity:  90.56 , specificity:  92.04 , f1-score:  86.82\n",
      "\n",
      "\n",
      "###### Metrics for Fold  4  ######\n",
      "\n",
      "acc =  90.69\n",
      "              sensitivity  specificity      precision      f1-score\n",
      "\n",
      "Class Normal:  98.2 ,        95.11 ,        94.69 ,        96.42\n",
      "\n",
      "Class Early:   0.0 ,        100.0 ,        0.0 ,        0.0\n",
      "\n",
      "Class Late:    98.66 ,        87.76 ,        86.88 ,        92.4\n",
      "\n",
      "\n",
      "##### Average Performance Metrics for Fold  4  #####\n",
      "\n",
      "precision:  83.73 sensitivity:  90.69 , specificity:  92.18 , f1-score:  87.03\n",
      "\n",
      "\n",
      "###### Metrics for Fold  5  ######\n",
      "\n",
      "acc =  90.21\n",
      "              sensitivity  specificity      precision      f1-score\n",
      "\n",
      "Class Normal:  98.61 ,        93.54 ,        93.16 ,        95.81\n",
      "\n",
      "Class Early:   0.0 ,        100.0 ,        0.0 ,        0.0\n",
      "\n",
      "Class Late:    97.66 ,        88.45 ,        87.26 ,        92.17\n",
      "\n",
      "\n",
      "##### Average Performance Metrics for Fold  5  #####\n",
      "\n",
      "precision:  82.99 sensitivity:  90.21 , specificity:  91.79 , f1-score:  86.43\n",
      "\n",
      "#### AVERAGE PERFORMANCE OVER ALL FOLDS ####\n",
      "\n",
      "\n",
      "precision:  83.37 sensitivity:  90.46 , specificity:  92.0 , f1-score:  86.74\n",
      "\n",
      "[ 83.37 ,  90.46 ,  92.0 ,  86.74 ]\n",
      "\n",
      " overall accuracy of model =  90.46\n"
     ]
    }
   ],
   "source": [
    "# all performance metrics for each fold and their averages\n",
    "\n",
    "perf = np.zeros(5)\n",
    "\n",
    "for i in range(1,6):\n",
    "    perf += print_performance_average_each_model(sim,i)\n",
    "perf = perf/5\n",
    "\n",
    "print('\\n#### AVERAGE PERFORMANCE OVER ALL FOLDS ####\\n\\n\\nprecision: ',round(perf[0],2),'sensitivity: ',round(perf[1],2), \", specificity: \",round(perf[2],2), \", f1-score: \", round(perf[3],2))   \n",
    "print('\\n[',round(perf[0],2),', ',round(perf[1],2), \", \",round(perf[2],2), \", \", round(perf[3],2),\"]\")   \n",
    "print('\\n overall accuracy of model = ', round(perf[4],2))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
